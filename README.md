# HSE-AI-24-ML-Pro
AI_HW1_Regression_with_inference_pro.ipynb

В целом AI_HW1_Regression_with_inference_pro.ipynb показываем всю работу по данной задачи, свёл основные выводы здесь:

    Анализ данных: ProfileReport Выводы по дашборду:

Дубли:Dataset has 493 (7.0%), пропуски 2.9%
Влияния столбоц и из корреляция ** Высокая корреляция: km_driven-year selling_price - transmission and 1 other fields
transmission - selling_price year - km_driven and 1 other fields seller_type "перекос данных" (51.8%)
Описание типов данных, текст, категориальные (transmission,owner)

Тренировочном и тестовом наборах данных есть схожие распределения для большинства переменных, но есть и небольшие различия (например, в возрасте автомобилей и пробеге), которые могут быть полезными для анализа.
В столбцах, таких как selling_price и km_driven, есть разница между средним и медианой, что указывает на асимметричные распределения или наличие выбросов.
Различия между тренингом и тестом могут указывать на небольшие различия в выборке, что важно учитывать при построении модели, так как это может повлиять на её обобщающие способности

    Можно ли предположить на основе распределений связь признаков с целевой переменной?
Для selling_price прослеживается линейная зависимость с max_power затем torque_value и после engine
✈ Можно ли предположить на основе распределений выдвинуть гипотезу о корреляциях признаков?
Парные графики играют важную роль в визуализации данных: Тенденции: линейных или нелинейных связей, которые предполагают предсказуемость. К примеру очень ярко выражена torque_value&max_power, есть обраные линейные зависимости к примеру mileage&engine
Конечно, по диагонале распределение нормальное распереление показателей

    Какие 2 признака наименее скоррелированы между собой?
year&min_rpm_range
    ✈ Между какими наблюдается довольно сильная положительная линейная зависимость?
torque_value& max_power
    ✈ Правильно ли, опираясь на данные, утверждать, что чем меньше год, тем, скорее всего, больше километров проехала машина к дате продажи?
year<< -> mileage>> - явной зависимости нет, если бы были доп. параметры к примеру "в такси" и т.д. то может быть :)


Всегда полезно изучить связь между переменными с помощью диаграммы рассеяния. Коэффициенты корреляции измеряют только линейные (Пирсона) или монотонные (Спирмена) отношения.

Нашёл реализацию по визуализации зависимостей более расширенную:
![ДЗ_1_X](https://github.com/user-attachments/assets/f0e174af-ea60-4ca7-954e-1466e5a974fa)

Формула для расчёта R2:
![ДЗ_1_Задание 12](https://github.com/user-attachments/assets/79b91ca5-a299-4252-96a5-9468651e9522)


    Adjusted R2 = R2 - [(1- R2)*(p/n-p-1)]

Скорректированный R-квадрат сравнивает объяснительную силу регрессионных моделей, которые содержат разное количество признаков. Предположим, вы сравниваете модель с пятью признаками с более высоким R-квадрат с моделью с одним признаком. Имеет ли модель с пятью признаков более высокий R-квадрат, потому что она лучше? Или R-квадрат выше, потому что у нее больше признаков?

Просто сравнить скорректированные значения R-квадрата, чтобы узнать это
Скорректированный R-квадрат — это модифицированная версия R-квадрата, скорректированная с учетом количества признаков в модели.
Скорректированный R-квадрат увеличивается только в том случае, если новый признак улучшает модель больше, чем можно было бы ожидать случайно.
Он уменьшается, когда признак не улучшает модель, чем можно было бы ожидать случайно.

Результаты R2 (Train&Test для различных подходов): 
L - LinearRegression
|StandardScaler | lasso       | ElasticNet  | L0-регуляр  | L,+кат.фичи |L,+квад.завис|L,year*engine|L,удалимвыброс|L,Best Result|PL+кат+SL-r  |PL+кат+фичи  |
| ------------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | -----------  | ----------- | ----------- | ----------- |
| 0.5922591702  | 0.59221485  | 0.59215455  | 0.59225917  | 0.77689359  | 0.79206609  | 0.82376518  | 0.828061208  | 0.825967516 | 0.951389605 | 0.999999935 |
| 0.5941419794  | 0.59270368  | 0.59104986  | 0.59414197  | 0.78861961  | 0.79599194  | 0.81247315  | 0.738242526  | 0.825967516 | 0.955018386 | 0.999999027 |
|               |             |             |             |             |             |             |              |             | MSE Train   |    18398.62 |
|               |             |             |             |             |             |             |              |             | MSE Test    |   559163.62 |

    Модель с  L0 -регуляризаицей
    
Использовали Lasso с разными значениями alpha для отбора признаков. Чем выше значение alpha, тем больше коэффициентов будет занулено.
Оценивали модель после каждого изменения значения alpha на тренировочных и тестовых данных, вычисляя метрики R2
При слишком низком alpha (например, 0.01), модель использует все признаки, что может привести к переобучению, особенно если данных слишком мало или признаки сильно коррелируют.
При большем alpha модель становится более обобщенной, так как удаляет незначительные признаки, что может привести к увеличению Test R² и снижению Train R², что говорит о лучшем обобщении модели.

    Добавляем категориальные фичи

Однако важно помнить, что OHE увеличивает размерность данных
Проверить тип строковый или категориальный
На тренировочных данных и тестовых данных нужно обучать трансформер только на тренировочных данных
Когда мы применяем One-Hot Encoding, для каждого уникального значения категории создается отдельный столбец. Однако, чтобы избежать проблемы мультиколлинеарности (когда признаки сильно коррелируют друг с другом), мы обычно удаляем один столбец drop='first'
Удаление неважных признаков после OHE должно быть обоснованным и учитывать тип модели, которую вы используете
В деревьях решений и ансамблях деревьев признаки могут быть важными, даже если их веса малы в линейной модели, и удаление таких признаков может ухудшить качество модели.

    Feature Engineering

Квадратичные, произведение фич даёт хороший прирост.
А вот удаление выбросов очень негативно влияет на модель, хотя на обучающихся данных результат есть

    Вывод

Линейная не входит в состояние переабучения и новые фичи (сложные дают хороший результат: квадратичные, умножение фича1*фича2, всё это видно из графиков зависимости)
Полиномиальная регрессия повышает точность, предоставив возможность линейной модели лучше подстроиться под данные. Это может привести к лучшему предсказанию, поскольку модель способна учитывать более высокие степени признаков.

Использование полиномиальных признаков позволяет избежать сложных манипуляций с исходными данными и помогает удерживать простоту модели, поскольку использование PolynomialFeatures позволяет эффективно расширить пространство признаков для линейной модели.

PolynomialFeatures является расширением, которое позволяет линейной регрессии работать с более сложными (нелинейными) зависимостями между признаками. 
В некоторых случаях это может сделать модель более точной, но важно следить за уровнем сложности модели, чтобы избежать переобучения.

Таким образом, PolynomialFeatures лучше, когда:

В данных есть явные или потенциальные нелинейные зависимости.
Линейная модель сама по себе не способна отобразить сложную структуру данных.
LinearRegression остается основным методом, который используется для создания линейных моделей, но когда данные требуют более сложной структуры, сочетание PolynomialFeatures и LinearRegression может быть мощным инструментом.


    
    API

API Structure: (folder HW1\)
  * ML_AppTest.py - тест для api сервисов
  * api_Regression.py - api сервис
  мmodel.pkl - модель
  * scaler.pkl - стандартизатор
  * data.csv - данные
  * response.csv - результат

Результат работы тестов:
  
  http://localhost:8000/test API Response:200 JSON Response 0.0
  
  http://localhost:8000/predict_item API Response:200 JSON Response 20155.700554678333
  
  http://localhost:8000/predict_items_csv API Response:200
  
  http://localhost:8000/predict_items API Response:200 JSON Response [20153.815641699475, 1720578.6110874433]

Результат файла ответа:
name,year,km_driven,fuel,seller_type,transmission,owner,mileage,engine,max_power,torque,seats,selling_price,**predicted_price**

Mahindra Xylo E4 BS IV,2010,168000,Diesel,Individual,Manual,First Owner,14 kmpl,2498,112 bhp,260 Nm at 1800-2200 rpm,7.0,229999.0,**20153.815641699475**

Mahindra Xylo E4 BS IV,2018,30000,Diesel,Individual,Manual,Second,20 kmpl,1800 cc,140 bhp,180 Nm,5.0,120000.0,**837805.7999319454**

API Video: 
![HW1_1](https://github.com/user-attachments/assets/d4234a07-8ed4-4566-93c8-f9000dd116da)

На фото по ссылке — сэр кот преподавателя
